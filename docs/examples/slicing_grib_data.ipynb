{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c021c8",
   "metadata": {},
   "source": [
    "# Slicing and dicing GRIB data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f67698",
   "metadata": {},
   "source": [
    "## Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9087e85f",
   "metadata": {},
   "source": [
    "A GRIB file consists of a sequence of self-contained GRIB *messages*. A GRIB file is represented as a *Fieldset* object in Metview. Each message contains the data for a single *field*, e.g. a single parameter generated at a single time for a single forecast step. A field contains a set of *gridpoints* geographically distributed in some way, plus metadata such as the parameter, the generation time, the forecast step and the centre that generated the data. A field may be plotted on a map, and a Fieldset may be plotted as an animation on a map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d2c76f",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b61b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import metview as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not strictly necessary to tell Metview that we're running in a Jupyter notebook,\n",
    "# but we will call this function so that we can specify a larger font size\n",
    "mv.setoutput('jupyter', output_width=700, output_font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207249af",
   "metadata": {},
   "source": [
    "## Reading and inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf8dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mv.read('grib_to_be_sliced.grib')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f3d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef423bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0758dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d031f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe('lsm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388b502",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ls()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd4e15f",
   "metadata": {},
   "source": [
    "# Field selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967dbb5c",
   "metadata": {},
   "source": [
    "## Field selection through indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first field (0-based indexing)\n",
    "print(data[0])\n",
    "data[0].ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the fourth field (0-based indexing)\n",
    "data[3].ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the last field\n",
    "data[-1].ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index with numpy array\n",
    "indices = np.array([1, 46, 27, 180])\n",
    "data[indices].ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538498db",
   "metadata": {},
   "source": [
    "## Field selection through slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select fields 4 to 7\n",
    "data[4:8].ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8a7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select fields 4 to 7, step 2\n",
    "data[4:8:2].ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e6bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the last 5 fields\n",
    "data[-5:].ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b127034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the fields' order\n",
    "data[::-1].ls()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ac9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign this to a variable and write to disk\n",
    "rev = data[::-1]\n",
    "rev.write('reversed.grib')\n",
    "print(rev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2163f749",
   "metadata": {},
   "source": [
    "## Field selection through metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ee0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select() method, various ways\n",
    "data.select(shortName='r').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a72d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select(shortName='r', level=[500, 850]).ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the selection criteria into a dict, then modify it before using\n",
    "# useful for programatically creating selection criteria\n",
    "criteria = {\"shortName\": \"z\", \"level\": [500, 850]}\n",
    "criteria[\"level\"] = 300\n",
    "data.select(criteria).ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorthand way of expressing parameters and levels\n",
    "data['r500'].ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04559be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify units - useful if different level types in the same fieldset\n",
    "data['r300hPa'].ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82572357",
   "metadata": {},
   "source": [
    "## Combining fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 4 fieldsets - one will be from another GRIB file to show that we can\n",
    "# combine fields from any number of different files\n",
    "\n",
    "a = data[5]\n",
    "b = data[78:80]\n",
    "c = data['z']\n",
    "d = mv.read('reversed.grib')[0]\n",
    "print(a, b, c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c12536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Fieldset out of existing ones\n",
    "combined = mv.merge(a, b, c, d)\n",
    "combined.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8005b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the Fieldset constructor to do the same thing from a\n",
    "# list of Fieldsets\n",
    "combined = mv.Fieldset(fields=[a, b, c, d])\n",
    "combined.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f8da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to an existing Fieldset - unlike the other functions,\n",
    "# this modifies the input Fieldset\n",
    "# let's use it in a loop to construct a new Fieldset\n",
    "\n",
    "new = mv.Fieldset() # create an empty Fieldset\n",
    "for x in [a,b,c,d]:\n",
    "    print('appending', x)\n",
    "    new.append(x)\n",
    "    print(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce9ea4",
   "metadata": {},
   "source": [
    "# Point selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf88d5d",
   "metadata": {},
   "source": [
    "## Area cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf79db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first select 2m temperature and plot it to see what we've got\n",
    "few_fields = data.select(shortName='2t')\n",
    "mv.plot(few_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6047ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an area [N,W,S,E]\n",
    "data_area = [70, -25, 28, 45]\n",
    "data_on_subarea = mv.read(data=few_fields, area=data_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b24373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the filelds to see\n",
    "mv.plot(data_on_subarea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccac302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some automatic styling and zoom into the area\n",
    "margins = [5, -5, -5, 5]\n",
    "view_area = [a + b for a, b in zip(data_area, margins)]\n",
    "view = mv.geoview(map_area_definition=\"corners\", area=view_area)\n",
    "cont_auto = mv.mcont(legend=True, contour_automatic_setting=\"ecmwf\", grib_scaling_of_derived_fields=True)\n",
    "mv.plot(view, data_on_subarea, cont_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35f91a",
   "metadata": {},
   "source": [
    "## Point reduction with regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce32b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the data points to see what the grid looks like\n",
    "gridpoint_markers = mv.mcont(\n",
    "    contour                          = \"off\",\n",
    "    contour_grid_value_plot          = \"on\",\n",
    "    contour_grid_value_plot_type     = \"marker\",\n",
    "    contour_grid_value_marker_height = 0.2,\n",
    "    contour_grid_value_marker_index  = 15,\n",
    "    )\n",
    "mv.plot(view, data_on_subarea[0], gridpoint_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid to a lower-resolution octahedral reduced Gaussian grid\n",
    "lowres_data = mv.read(data=data_on_subarea, grid=\"O80\")\n",
    "mv.plot(view, lowres_data[0], gridpoint_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac779ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid to a regular lat/lon grid\n",
    "lowres_data = mv.read(data=data_on_subarea, grid=[3, 3]) # 3 degrees\n",
    "mv.plot(view, lowres_data[0], gridpoint_markers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9b9b53",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9d977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masking in Metview means defining an area and either:\n",
    "#   creating a field with 1s inside the area and 0s outside (missing=False)\n",
    "#   or\n",
    "#   turning the values outside the area into missing values (missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use temperature data at step 0 to be masked\n",
    "t0 = data.select(shortName='2t', step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbacd0a1",
   "metadata": {},
   "source": [
    "### Geographic masking\n",
    "This is where we define regions of a field to be preserved, while the points outside those regions are filled with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf8837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a rectangular mask\n",
    "rect_masked_data = mv.mask(t0, [48, -12, 63, 5], missing=True) # [N,W,S,E]\n",
    "mv.plot(view, rect_masked_data, cont_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a circular mask - centre in lat/lon, radius in m\n",
    "circ_masked_data = mv.rmask(t0, [45, -15, 800*1000], missing=True) # [N,W,S,E]\n",
    "mv.plot(view, circ_masked_data, cont_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon area - we will use a shapefile from Magics\n",
    "import shapefile # pip install pyshp\n",
    "\n",
    "# download a shapefile with geographic shapes\n",
    "filename = \"ne_50m_land.zip\"\n",
    "if not mv.exist(filename):\n",
    "    mv.gallery.load_dataset(filename)\n",
    "\n",
    "sf = shapefile.Reader(\"ne_50m_land.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86d29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the list of points for the Great Britain polygon\n",
    "shapes = sf.shapes()\n",
    "points = shapes[135].points  # GB\n",
    "lats = np.array([p[1] for p in points])\n",
    "lons = np.array([p[0] for p in points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078fbe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_masked_data = mv.poly_mask(t0, lats, lons, missing=True)\n",
    "mv.plot(view, poly_masked_data, cont_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b9f640",
   "metadata": {},
   "source": [
    "### Frames\n",
    "Frames are useful to supply boundary conditions to a local area model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe34b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the frame parameter is the width of the frame in degrees\n",
    "data_frame = mv.read(data=t0, area=data_area, frame=5, grid=[1,1])\n",
    "mv.plot(data_frame, cont_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9da64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean value for original data    :', t0.average())\n",
    "print('mean value for rect masked data :', rect_masked_data.average())\n",
    "print('mean value for circ masked data :', circ_masked_data.average())\n",
    "print('mean value for poly masked data :', poly_masked_data.average())\n",
    "print('mean value for framed data      :', data_frame.average())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fe3c7",
   "metadata": {},
   "source": [
    "### Computational masking\n",
    "This is where we generate masks consisting of 1s where the points are inside a given region (or satisfy some other criteria) and 0s otherwise. We can then combine these and use them to provide a missing value mask to any field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c162c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contouring for 0 and 1 values\n",
    "mask_1_and_0_contouring = mv.mcont(\n",
    "    legend=\"on\",\n",
    "    contour=\"off\",\n",
    "    contour_level_selection_type=\"level_list\",\n",
    "    contour_level_list=[0, 1, 2],\n",
    "    contour_shade=\"on\",\n",
    "    contour_shade_technique=\"grid_shading\",\n",
    "    contour_shade_max_level_colour=\"red\",\n",
    "    contour_shade_min_level_colour=\"yellow\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3490ff30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a rectangular mask\n",
    "rect_masked_data = mv.mask(t0, [48, -12, 63, 5], missing=False) # [N,W,S,E]\n",
    "mv.plot(view, rect_masked_data, mask_1_and_0_contouring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c4e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a circular mask - centre in lat/lon, radius in m\n",
    "circ_masked_data = mv.rmask(t0, [45, -15, 800*1000], missing=False) # [N,W,S,E]\n",
    "mv.plot(view, circ_masked_data, mask_1_and_0_contouring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da873ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will now define a mask based on the land-sea mask field; let's plot it first\n",
    "lsm = data.select(shortName='lsm')\n",
    "lsm_contour = mv.mcont(\n",
    "    legend=True,\n",
    "    contour=False,\n",
    "    contour_label=False,\n",
    "    contour_max_level=1.1,\n",
    "    contour_shade='on',\n",
    "    contour_shade_technique='grid_shading',\n",
    "    contour_shade_method='area_fill',\n",
    "    contour_shade_min_level_colour='white',\n",
    "    contour_shade_max_level_colour='brown',\n",
    ")\n",
    "mv.plot(lsm, lsm_contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25af07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the purposes of our mask, consider lsm>0.5 to be land\n",
    "land = lsm > 0.5\n",
    "mv.plot(land, mask_1_and_0_contouring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820691ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the masks with the 'or' operator (only useful for 1/0 masks)\n",
    "# use '&' to compute the intersection of masks\n",
    "combined_mask_data = rect_masked_data | circ_masked_data | land\n",
    "mv.plot(combined_mask_data, mask_1_and_0_contouring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c18236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this mask to replace 0s with missing values in the original data\n",
    "combined_mask_data = mv.bitmap(combined_mask_data, 0) # replace 0 with missing vals\n",
    "masked_data = mv.bitmap(t0, combined_mask_data) # copy missing vals over\n",
    "mv.plot(masked_data, cont_auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24cf839",
   "metadata": {},
   "source": [
    "## Vertical profiles\n",
    "Vertical profiles can be extracted from GRIB data for a given point or area (with spatial averaging) for each timestep separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot a profile for each forecast step of temperature\n",
    "\n",
    "# we will extract one Fieldset for each time step - each of these Fieldsets\n",
    "# will contain all the vertical levels of temperature data for that time step\n",
    "# we will end up with a list of these Fieldsets and plot a profile for each\n",
    "\n",
    "steps = mv.unique(mv.grib_get_long(data, 'step'))\n",
    "data_for_all_steps = [data.select(shortName='t', step=s) for s in steps]\n",
    "for f in data_for_all_steps:\n",
    "    print(f.grib_get(['step', 'level']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b68ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will plot the profile for each step in a different colour - generate a list\n",
    "# of 'mgraph' definitions, each using a different colour, for this purpose\n",
    "nsteps = len(steps)\n",
    "colour_inc = 1/nsteps\n",
    "graph_colours = [mv.mgraph(legend=True,\n",
    "                           graph_line_thickness=2,\n",
    "                           graph_line_colour='HSL('+str(360*s*colour_inc)+',1,0.45)') for s in range(len(steps))]\n",
    "\n",
    "# define a nice legend\n",
    "legend = mv.mlegend(\n",
    "    legend_display_type=\"disjoint\",\n",
    "    legend_entry_plot_direction=\"column\",\n",
    "    legend_text_composition=\"user_text_only\",\n",
    "    legend_entry_plot_orientation=\"top_bottom\",\n",
    "    legend_border_colour=\"black\",\n",
    "    legend_box_mode=\"positional\",\n",
    "    legend_box_x_position=2.5,\n",
    "    legend_box_y_position=4,\n",
    "    legend_box_x_length=5,\n",
    "    legend_box_y_length=8,\n",
    "    legend_text_font_size=0.4,\n",
    "    legend_user_lines=[str(int(s)) for s in steps],\n",
    ")\n",
    "\n",
    "# define the axis labels\n",
    "vertical_axis = mv.maxis(\n",
    "    axis_type=\"position_list\",\n",
    "    axis_tick_position_list=data_for_all_steps[0].grib_get_long('level')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, the magic happens here - the vertical profile view extracts the data\n",
    "# at the given point at each level\n",
    "vpview = mv.mvertprofview(\n",
    "    input_mode=\"point\",\n",
    "    point=[-50, -70], # lat,lon\n",
    "    bottom_level=1000,\n",
    "    top_level=100,\n",
    "    vertical_scaling=\"log\",\n",
    "    level_axis=vertical_axis\n",
    ")\n",
    "mv.plot(vpview, list(zip(data_for_all_steps, graph_colours)), legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f699075",
   "metadata": {},
   "source": [
    "## Thermodynamic profiles\n",
    "\n",
    "A special version of the point profile extraction is implemented by [mthermo_grib()](../gen_files/icon_functions/mthermo_grib.rst), which generates input data for thermodynamic diagrams (e.g. tephigrams). Metview is \n",
    "able to use these profiles to compute thermodynamic parcel paths and stability parameters like CAPE and CIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8219e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract temperature and specific humidity for all the levels \n",
    "# for a given timestep\n",
    "tq_data = data.select(shortName=[\"t\", \"q\"], step=0)\n",
    "\n",
    "# extract thermo profile\n",
    "location = [33, -100]  # lat, lon\n",
    "prof = mv.thermo_grib(coordinates=location, data=tq_data)\n",
    "\n",
    "# compute parcel path - maximum cape up to 700 hPa from the surface\n",
    "parcel = mv.thermo_parcel_path(prof, {\"mode\": \"most_unstable\", \"top_p\": 700})\n",
    "\n",
    "# create plot object for parcel areas and path\n",
    "parcel_area = mv.thermo_parcel_area(parcel)\n",
    "parcel_vis = mv.xy_curve(parcel[\"t\"], parcel[\"p\"], \"charcoal\", \"dash\", 6)\n",
    "\n",
    "# define temperature and dewpoint profile style\n",
    "prof_vis = mv.mthermo(\n",
    "    thermo_temperature_line_thickness=5, thermo_dewpoint_line_thickness=5\n",
    ")\n",
    "\n",
    "# define a skew-T thermodynamic diagram view\n",
    "view = mv.thermoview(type=\"skewt\")\n",
    "\n",
    "# plot the profile, parcel areas and parcel path together\n",
    "mv.plot(view, parcel_area, prof, prof_vis, parcel_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e4cc9",
   "metadata": {},
   "source": [
    "## Vertical cross sections\n",
    "\n",
    "For a **vertical cross section** data is extracted along a transect line for all the vertical levels for a given timestep. We can choose wether we want to generate the cross section by **interpolating** the values onto the transect line or use the **nearest gridpoint** method.\n",
    "\n",
    "### Using the cross section view\n",
    "\n",
    "The simplest way to generate a cross section is to use the cross section view ([mxsectview()](../gen_files/icon_functions/mxsectview.rst)), which will automatically preform the data extraction on the input GRIB fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d74c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the cross section line\n",
    "line=[66, -44, 38,-30] # lat1,lon1,lat2,lon2\n",
    "\n",
    "# define the cross section view\n",
    "cs_view = mv.mxsectview(\n",
    "    bottom_level=1000,\n",
    "    top_level=100,\n",
    "    line=line,\n",
    "    horizontal_point_mode=\"interpolate\",\n",
    ")\n",
    "\n",
    "# extract temperature and relative humidity for the first timestep\n",
    "# for all the levels. We scale temperature values from to Celsius units\n",
    "# for plotting\n",
    "t = data.select(shortName=\"t\", step=0) - 273.16\n",
    "r = data.select(shortName=\"r\", step=0)\n",
    "\n",
    "# define the contouring styles for the cross section\n",
    "cont_xs_t = mv.mcont(\n",
    "    contour_line_style           = \"dash\",\n",
    "    contour_line_colour          = \"black\",\n",
    "    contour_highlight            = \"off\",\n",
    "    contour_level_selection_type = \"interval\",\n",
    "    contour_interval             = 5\n",
    "    )\n",
    "\n",
    "cont_xs_r = mv.mcont(\n",
    "    contour_automatic_setting = \"style_name\",\n",
    "    contour_style_name        = \"sh_grnblu_f65t100i15_light\",\n",
    "    legend                    = \"on\"\n",
    "    )\n",
    "\n",
    "# generate the cross section plot. The computations are automatically performed according\n",
    "# to the settings in the view.\n",
    "mv.plot(cs_view, r, cont_xs_r, t, cont_xs_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbaad62",
   "metadata": {},
   "source": [
    "### Accessing the cross section data\n",
    "\n",
    "The actual results of the cross section computations are stored in a custom NetCDF format. If we want to access it [mcross_sect()](../gen_files/icon_functions/mcross_sect.rst) should be used instead of the view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cross section data for temperature\n",
    "xs_t = mv.mcross_sect( \n",
    "    data=t, \n",
    "    bottom_level=1000,\n",
    "    top_level=100,\n",
    "    line=line,\n",
    "    horizontal_point_mode=\"interpolate\")\n",
    "\n",
    "# write netCDF  data to disk\n",
    "mv.write(\"xs_t.nc\", xs_t)\n",
    "\n",
    "# dump the data contents\n",
    "import xarray as xr\n",
    "ds_t= xr.open_dataset(\"xs_t.nc\")\n",
    "ds_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e499cb99",
   "metadata": {},
   "source": [
    "### Plotting the cross section data and using it for single level slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53125f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tropopause pressure (it is a single level field)\n",
    "trpp = data.select(shortName=\"trpp\", step=0)\n",
    "\n",
    "# using the temperature cross section object we can extract a slice from trpp along the\n",
    "# transect line and build a curve object out of it. The pressure has to be scaled\n",
    "# from Pa to hPa.\n",
    "trpp_curve = mv.xs_build_curve(xs_t, trpp/100, \"red\", \"solid\", 3)\n",
    "\n",
    "# directly plot the temperature cross section data and the trpp curve\n",
    "mv.plot(xs_t, cont_xs_t,  trpp_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa62ec6f",
   "metadata": {},
   "source": [
    "## Average vertical cross sections\n",
    "\n",
    "This is a variant of the vertical cross section where either a **zonal** or **meridional** average is computed for all the levels in a given timestep. Similarly to the cross section the input data can be directly plotted into a view ([maverageview()](../gen_files/icon_functions/maverageview.rst)) or passed on to [mxs_average()](../gen_files/icon_functions/mxs_average.rst) to generate average cross section NetCDF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba54d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the average view for a global zonal mean\n",
    "av_view = mv.maverageview(\n",
    "    top_level=100,\n",
    "    bottom_level=1000,\n",
    "    vertical_scaling=\"log\",\n",
    "    area=[90,-180, -90, 180], # N, W, S, E\n",
    "    direction=\"ew\"\n",
    ")\n",
    "\n",
    "# extract temperature for the first timestep for all the levels. We scale\n",
    "# temperature values to Celsius units for plotting\n",
    "t = data.select(shortName=\"t\", step=0)\n",
    "t = t - 273.16\n",
    "\n",
    "# define the contouring styles for the zonal mean cross section\n",
    "cont_zonal_t = mv.mcont(\n",
    "    contour_automatic_setting = \"style_name\",\n",
    "    contour_style_name        = \"sh_all_fM80t56i4_v2\",\n",
    "    legend                    = \"on\"\n",
    "    )\n",
    "    \n",
    "# generate the average cross section plot. The computations are automatically \n",
    "# performed according to the settings in the view.\n",
    "mv.plot(av_view, t, cont_zonal_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e6f420",
   "metadata": {},
   "source": [
    "## Hovmoeller diagrams\n",
    "\n",
    "**Hovmoeller** diagrams are special sections for (mostly single level) fields where one axis is always the time while the other one can be derived in various ways. Metview supports 3 flavours of it: \n",
    "- area Hovmoellers\n",
    "- vertical Hovmoellers \n",
    "- line Hovmoellers\n",
    "\n",
    "### Area Hovmoeller diagrams\n",
    "\n",
    "In this diagram type for each date and time either **zonal or meridional averaging** is performed on the data. The example below shows a Hovmoeller diagram with longitude on the horizontal axis and time on the vertical axis. Each point in the plot is a meridional average performed for temerature on 500 hPa at the given time in North-South (meridional) direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Hovmoeller view for an area in the North-Atlantic and\n",
    "# choose meridional averaging\n",
    "view = mv.mhovmoellerview(\n",
    "    type=\"area_hovm\",\n",
    "    area=[70, -70, 40, 0],\n",
    "    average_direction=\"north_south\",\n",
    ")\n",
    "\n",
    "# extract temperature on 500 hPa for all the timestep and \n",
    "# convert it into Celsius units for plotting\n",
    "t = data.select(shortName=\"t\", level=500)\n",
    "t = t - 273.16\n",
    "\n",
    "# define contour shading\n",
    "cont_hov_t = mv.mcont(\n",
    "    legend                       = \"on\",\n",
    "    contour                      = \"off\",\n",
    "    contour_level_selection_type = \"interval\",\n",
    "    contour_max_level            = -12,\n",
    "    contour_min_level            = -23,\n",
    "    contour_interval             = 1,\n",
    "    contour_label                = \"off\",\n",
    "    contour_shade                = \"on\",\n",
    "    contour_shade_colour_method  = \"palette\",\n",
    "    contour_shade_method         = \"area_fill\",\n",
    "    contour_shade_palette_name   = \"m_purple2_11\"\n",
    "    )\n",
    "\n",
    "# generate the area Hovmoeller plot. The computations are automatically \n",
    "# performed according to the settings in the view.\n",
    "mv.plot(view, t, cont_hov_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ae31c",
   "metadata": {},
   "source": [
    "### Vertical Hovmoeller diagrams\n",
    "\n",
    "In this diagram type the horizontal axis is time and the vertical axis is a vertical co-ordinate. The data is extracted for a given location or generated by spatial averaging over an area. The example below shows the temperature forecast evolution for a selected point having pressure as the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5604aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a vertical Hovmoeller view for a location. The point data \n",
    "# is extracted with the nearest gridpoint method \n",
    "view = mv.mhovmoellerview(\n",
    "    type=\"vertical_hovm\",\n",
    "    bottom_level=1000,\n",
    "    top_level=200,\n",
    "    input_mode=\"nearest_gridpoint\",\n",
    "    point=[-50, -70],\n",
    ")\n",
    "\n",
    "# extract the temperature on all the levels and timesteps. Values \n",
    "# scaled to Celsius units for plotting\n",
    "t = data.select(shortName=\"t\")\n",
    "t = t - 273.16\n",
    "\n",
    "# generate the vertical Hovmoeller plot. The computations are automatically \n",
    "# performed according to the settings in the view.\n",
    "mv.plot(view, t, cont_zonal_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8edc2a3",
   "metadata": {},
   "source": [
    "### Line Hovmoeller diagrams\n",
    "\n",
    "In this diagram type the data is extracted along a transect line from a single level field for multiple dates and times. In the resulting plot one axis is time while the other goes along the transect line. The example below shows a line Hovmoeller diagram for the 2m temperature forecast evolution along a line across Lake Victoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df79c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a line Hovmoeller view for a transect line across Lake Victoria\n",
    "hov_view = mv.mhovmoellerview(\n",
    "    type=\"line_hovm\",\n",
    "    line=[0.2, 31.6, -2, 34.5],  # N,W,S,E\n",
    "    resolution=0.25,\n",
    "    swap_axis=\"no\"\n",
    ")\n",
    "\n",
    "# extract the 2m temperature on all the levels and timesteps. Values \n",
    "# scaled to Celsius units for plotting\n",
    "t = data.select(shortName=\"2t\")\n",
    "t = t -273.16\n",
    "\n",
    "# define contour shading for t2m\n",
    "t_cont = mv.mcont(\n",
    "    legend=\"on\",\n",
    "    contour=\"off\",\n",
    "    contour_level_selection_type=\"interval\",\n",
    "    contour_max_level=30,\n",
    "    contour_min_level=14,\n",
    "    contour_interval=1,\n",
    "    contour_label=\"off\",\n",
    "    contour_shade=\"on\",\n",
    "    contour_shade_colour_method=\"palette\",\n",
    "    contour_shade_method=\"area_fill\",\n",
    "    contour_shade_palette_name=\"m_orange_purple_16\",\n",
    ")\n",
    "\n",
    "# generate the line Hovmoeller plot. The computations are automatically \n",
    "# performed according to the settings in the view.\n",
    "mv.plot(hov_view, t, t_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e7a1a7",
   "metadata": {},
   "source": [
    "## Gridpoint selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e53578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value of single field at location\n",
    "r1000 = data['r1000']\n",
    "bologna_coords = [44.5, 11.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c53d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r1000.nearest_gridpoint(bologna_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05356a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more info about the point\n",
    "print(r1000.nearest_gridpoint_info(bologna_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c6e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value of multiple fields at a single location\n",
    "r = data['r']\n",
    "print(r.nearest_gridpoint(bologna_coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value of single field at multiple locations\n",
    "lats = np.array([10, 20, 30, 40])\n",
    "lons = np.array([45, 40, 35, 30])\n",
    "print(r1000.nearest_gridpoint(lats, lons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689385f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get value of multiple fields at multiple locations (returns 2d numpy array)\n",
    "lats = np.array([10, 20, 30, 40])\n",
    "lons = np.array([45, 40, 35, 30])\n",
    "print(r.nearest_gridpoint(lats, lons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate the value at the point (because it does not fall exactly on a grid point)\n",
    "print(r.interpolate(bologna_coords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e17784",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the lat/lon coordinates of three locations\n",
    "bologna_coords = [44.5, 11.3]\n",
    "bonn_coords    = [50.7, 7.1]\n",
    "reading_coords = [51.4, 0.98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a25fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract point data from these locations from the 2m temperature data\n",
    "t2m = data['2t']\n",
    "\n",
    "bologna_vals = t2m.nearest_gridpoint(bologna_coords)\n",
    "bonn_vals = t2m.nearest_gridpoint(bonn_coords)\n",
    "reading_vals = t2m.nearest_gridpoint(reading_coords)\n",
    "\n",
    "# extract the valid times for the data\n",
    "times = mv.valid_date(t2m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb379f4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "vaxis = mv.maxis(axis_title_text=\"Temperature, K\", axis_title_height=0.5)\n",
    "\n",
    "ts_view = mv.cartesianview(\n",
    "    x_automatic=\"on\",\n",
    "    x_axis_type=\"date\",\n",
    "    y_automatic=\"on\",\n",
    "    vertical_axis=vaxis,\n",
    ")\n",
    "\n",
    "# create the curves for all locations\n",
    "curve_bologna = mv.input_visualiser(\n",
    "    input_x_type=\"date\", input_date_x_values=times, input_y_values=bologna_vals\n",
    ")\n",
    "\n",
    "curve_bonn = mv.input_visualiser(\n",
    "    input_x_type=\"date\", input_date_x_values=times, input_y_values=bonn_vals\n",
    ")\n",
    "\n",
    "curve_reading = mv.input_visualiser(\n",
    "    input_x_type=\"date\", input_date_x_values=times, input_y_values=reading_vals\n",
    ")\n",
    "\n",
    "# set up visual styling for each curve\n",
    "common_graph = {\"graph_line_thickness\": 2, \"legend\": \"on\"}\n",
    "graph_bologna = mv.mgraph(common_graph, graph_line_colour=\"olive\", legend_user_text=\"Bologna\")\n",
    "graph_bonn = mv.mgraph(common_graph, graph_line_colour=\"blue\", legend_user_text=\"Bonn\")\n",
    "graph_reading = mv.mgraph(common_graph, graph_line_colour=\"red\", legend_user_text=\"Reading\")\n",
    "\n",
    "# customise the legend\n",
    "legend = mv.mlegend(legend_display_type=\"disjoint\", legend_text_font_size=0.5)\n",
    "\n",
    "# plot everything into the Cartesian view\n",
    "mv.plot(ts_view, curve_bologna, graph_bologna, curve_bonn, graph_bonn, curve_reading, graph_reading, legend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
